 # A scrape configuration containing exactly one endpoint to scrape from node_exporter running on a host:
     # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
     # metrics_path defaults to '/metrics'
     # scheme defaults to 'http'.


global:
  scrape_interval: 1m
  external_labels:
    cluster: "TEST-CLUSTER"
    replica: "REPLICA_1"

scrape_configs:
    # TODO template generation for different ports
    # Use thanos reload for that
    # Prometheus itself
    # This uses the static method to get metrics endpoints

    -   job_name: "node-exporter-job"
        honor_labels: false
        static_configs:
        -   targets: ["host-gateway:9100"]

    -   job_name: "cadvisor"
        honor_labels: false
        static_configs:
        - targets: ["host-gateway:8080"]
        metric_relabel_configs:
            # - source_labels: [__name__]
            #   regex: 'container_cpu_usage_seconds_total|container_memory_usage_bytes|thanos.*'
            #   action: keep
            # - source_labels: [container_label_com_docker_compose_config_hash,
            # dropping the id label results in out of order samples
            # - regex: 'container_label_com_docker_compose_.*|container_label_maintainer|image|id|instance'
            - regex: 'container_label_com_docker_compose_.*|container_label_maintainer|image|instance'
            # - regex: '(container_label_com_docker_compose_.*)|id'
              action: labeldrop
